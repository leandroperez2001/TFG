{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer df_sin_anomalos.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('df_sin_anomalos.csv')\n",
    "df_final = pd.read_csv(\"df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir en train y test segun indice_test.csv y indice_train.csv\n",
    "indice_test = pd.read_csv(\"indices_test.csv\")\n",
    "indice_train = pd.read_csv(\"indices_train.csv\")\n",
    "\n",
    "df_test = df_final.iloc[indice_test[\"0\"],:]\n",
    "df_train = df_final.iloc[indice_train[\"0\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_todos = df_test.drop(['TRT'], axis=1)\n",
    "y_test = pd.DataFrame(df_test[\"TRT\"])\n",
    "\n",
    "X_train_todos = df_train.drop(['TRT'], axis=1)\n",
    "y_train = pd.DataFrame(df_train[\"TRT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test_todos[[\"ARTERIOPATIA_PERIFERICA\",\"ENFERMEDAD_VASCULAR\",\"SAME_MAS_DE_2\",\"N_PASTILLAS_D_INICIO\",\"NEOPLASIA_NO\",\"ADE\",\"MONOCITOS\",\"DISLIPEMIA\",\"AMIODARONA\",\"EDAD\",\"INSUFICIENCIA_CARDIACA\",\"SAME-TT2R2_MAS3\",\"NEUTROFILOS\"]]\n",
    "X_train_final = X_train_todos[[\"ARTERIOPATIA_PERIFERICA\",\"ENFERMEDAD_VASCULAR\",\"SAME_MAS_DE_2\",\"N_PASTILLAS_D_INICIO\",\"NEOPLASIA_NO\",\"ADE\",\"MONOCITOS\",\"DISLIPEMIA\",\"AMIODARONA\",\"EDAD\",\"INSUFICIENCIA_CARDIACA\",\"SAME-TT2R2_MAS3\",\"NEUTROFILOS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"TRT_60\"] = 0\n",
    "y_train.loc[y_train[\"TRT\"] >= 60, \"TRT_60\"] = 1\n",
    "\n",
    "y_test[\"TRT_60\"] = 0\n",
    "y_test.loc[y_test[\"TRT\"] >= 60, \"TRT_60\"] = 1\n",
    "\n",
    "y_train[\"TRT_65\"] = 0\n",
    "y_train.loc[y_train[\"TRT\"] >= 65, \"TRT_65\"] = 1\n",
    "\n",
    "y_test[\"TRT_65\"] = 0\n",
    "y_test.loc[y_test[\"TRT\"] >= 65, \"TRT_65\"] = 1\n",
    "\n",
    "y_train[\"TRT_70\"] = 0\n",
    "y_train.loc[y_train[\"TRT\"] >= 70, \"TRT_70\"] = 1\n",
    "\n",
    "y_test[\"TRT_70\"] = 0\n",
    "y_test.loc[y_test[\"TRT\"] >= 70, \"TRT_70\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling + oversampling\n",
    "from imblearn.over_sampling import ADASYN\n",
    "sm = ADASYN(random_state=123)\n",
    "X_train_todos60, y_train_bi60t = sm.fit_resample(X_train_todos, y_train[\"TRT_60\"])\n",
    "X_train_final60, y_train_bi60 = sm.fit_resample(X_train_final, y_train[\"TRT_60\"])\n",
    "X_train_todos65, y_train_bi65t = sm.fit_resample(X_train_todos, y_train[\"TRT_65\"])\n",
    "X_train_final65, y_train_bi65 = sm.fit_resample(X_train_final, y_train[\"TRT_65\"])\n",
    "X_train_todos70, y_train_bi70t = sm.fit_resample(X_train_todos, y_train[\"TRT_70\"])\n",
    "X_train_final70, y_train_bi70 = sm.fit_resample(X_train_final, y_train[\"TRT_70\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# warnings\n",
    "import warnings\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# time\n",
    "import time\n",
    "\n",
    "\n",
    "# make scorer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "# roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scoring = {\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "def train_model_gridsearch2(model, X_train, X_val, y_train, y_val, params,DF):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring=scoring, refit=\"precision\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best params: \", grid.best_params_)\n",
    "    print(\"Best score: \", grid.best_score_)\n",
    "    start_time = time.time()\n",
    "    y_pred = grid.predict(X_val)\n",
    "    execution_time = (time.time() - start_time)\n",
    "    print(\"F1: \", f1_score(y_val, y_pred))\n",
    "    print(\"Precision: \", precision_score(y_val, y_pred))\n",
    "    print(\"Recall: \", recall_score(y_val, y_pred))\n",
    "    print(\"Balanced accuracy: \", accuracy_score(y_val, y_pred))\n",
    "    # negative predictive value\n",
    "    print(\"Negative predictive value: \", np.round(confusion_matrix(y_val, y_pred)[0][0]/(confusion_matrix(y_val, y_pred)[0][0]+confusion_matrix(y_val, y_pred)[1][0]), 2))\n",
    "    # positive predictive value\n",
    "    print(\"Positive predictive value: \", np.round(confusion_matrix(y_val, y_pred)[1][1]/(confusion_matrix(y_val, y_pred)[1][1]+confusion_matrix(y_val, y_pred)[0][1]), 2))\n",
    "    print()\n",
    "\n",
    "    # classification report\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    # confusion matrix con seaborn\n",
    "    cm = confusion_matrix(y_val,y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    # axes\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    # title\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "    \n",
    "    # plot roc curve\n",
    "    try:\n",
    "        y_pred_proba = grid.predict_proba(X_val)[::,1]\n",
    "        fpr, tpr, _ = roc_curve(y_val,  y_pred_proba)\n",
    "        auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        print(auc)\n",
    "        plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "        # axes\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        # linea diagonal en gris claro\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "        # titulo\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend(loc=4)\n",
    "        plt.show()\n",
    "        precision, recall, _ = precision_recall_curve(y_val, y_pred_proba)\n",
    "\n",
    "        # Plot the precision-recall curve\n",
    "        plt.plot(recall, precision, marker='.')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # predict probabilit\n",
    "        # reliability diagram\n",
    "        fop, mpv = calibration_curve(y_val, y_pred_proba, n_bins=10, normalize=True)\n",
    "        # plot perfectly calibrated\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        # plot model reliability\n",
    "        plt.plot(mpv, fop, marker='.')\n",
    "        plt.xlabel('Mean predicted value')\n",
    "        plt.ylabel('Fraction of positives')\n",
    "        plt.title('Calibration Curve')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        DF = DF.append({\"Modelo\": str(model), \"F1\": f1_score(y_val, y_pred), \"Precision\": precision_score(y_val, y_pred), \"Recall\": recall_score(y_val, y_pred), \"Balanced accuracy\": balanced_accuracy_score(y_val, y_pred), \"NPV\": np.round(confusion_matrix(y_val, y_pred)[0][0]/(confusion_matrix(y_val, y_pred)[0][0]+confusion_matrix(y_val, y_pred)[1][0]), 2), \"PPV\": np.round(confusion_matrix(y_val, y_pred)[1][1]/(confusion_matrix(y_val, y_pred)[1][1]+confusion_matrix(y_val, y_pred)[0][1]), 2), \"Time\": execution_time, \"AUC\": roc_auc_score(y_val, y_pred_proba),\"FPR\":fpr,\"TPR\":tpr,\"FOP\":fop,\"MPV\":mpv}, ignore_index=True)\n",
    "    except:\n",
    "        fpr, tpr, _ = roc_curve(y_val,  y_pred)\n",
    "        fop, mpv = calibration_curve(y_val, y_pred, n_bins=10, normalize=True)\n",
    "        precision, recall, _ = precision_recall_curve(y_val, y_pred)\n",
    "        DF = DF.append({\"Modelo\": str(model), \"F1\": f1_score(y_val, y_pred), \"Precision\": precision_score(y_val, y_pred), \"Recall\": recall_score(y_val, y_pred), \"Balanced accuracy\": balanced_accuracy_score(y_val, y_pred), \"NPV\": np.round(confusion_matrix(y_val, y_pred)[0][0]/(confusion_matrix(y_val, y_pred)[0][0]+confusion_matrix(y_val, y_pred)[1][0]), 2), \"PPV\": np.round(confusion_matrix(y_val, y_pred)[1][1]/(confusion_matrix(y_val, y_pred)[1][1]+confusion_matrix(y_val, y_pred)[0][1]), 2), \"Time\": execution_time, \"AUC\": roc_auc_score(y_val, y_pred),\"FPR\":fpr,\"TPR\":tpr,\"FOP\":fop,\"MPV\":mpv}, ignore_index=True)\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAME = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\",\"FPR\",\"TPR\",\"FOP\",\"MPV\",\"Cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS2 = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\", \"FPR\", \"TPR\", \"PR\", \"RE\",\"Cost\"])\n",
    "SIGNIFICATIVAS2 = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\", \"FPR\", \"TPR\", \"PR\", \"RE\",\"Cost\"])\n",
    "\n",
    "TODAS3 = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\", \"FPR\", \"TPR\", \"PR\", \"RE\",\"Cost\"])\n",
    "SIGNIFICATIVAS3 = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\", \"FPR\", \"TPR\", \"PR\", \"RE\",\"Cost\"])\n",
    "\n",
    "TODAS4 = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\", \"FPR\", \"TPR\", \"PR\", \"RE\",\"Cost\"])\n",
    "SIGNIFICATIVAS4 = pd.DataFrame(columns=[\"Modelo\", \"F1\", \"Precision\", \"Recall\", \"Balanced accuracy\", \"NPV\", \"PPV\", \"Time\", \"AUC\", \"FPR\", \"TPR\", \"PR\", \"RE\",\"Cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "#import gridsearchcv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# ada boost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# GAN network\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# no mostrar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "models2 = [AdaBoostClassifier(),LogisticRegression(),SVC(probability=True),MLPClassifier(),DecisionTreeClassifier(),KNeighborsClassifier()]\n",
    "models2_names = [\"AdaBoostClassifier\",\"LogisticRegression\",\"SVC\",\"MLPClassifier\",\"DecisionTreeClassifier\",\"KNeighborsClassifier\"]\n",
    "params2 = [{\"n_estimators\": [100, 200, 300, 400, 500], \"learning_rate\": [0.01, 0.1, 1, 10, 100], \"algorithm\": [\"SAMME\", \"SAMME.R\"]},\n",
    "           {},\n",
    "                {\"C\": [0.1, 1, 10, 100, 1000], \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \"gamma\": [\"scale\", \"auto\"]},\n",
    "                    {\"hidden_layer_sizes\": [(10,10,10), (100,100,100), (100,100), (3,5), (5,3)], \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], \"solver\": [\"lbfgs\", \"sgd\", \"adam\"], \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]},\n",
    "                        {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": [None, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"min_samples_split\": [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "                            {\"n_neighbors\": [3, 5, 7, 9, 11, 13, 15, 17, 19], \"weights\": [\"uniform\", \"distance\"], \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]}]\n",
    "\n",
    "# entrenar los modelos con el dataset de entrenamiento y validarlos con el dataset de validacion\n",
    "for i in range(len(models2)):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    print(\"Model: \", models2_names[i])\n",
    "    TODAS2 = train_model_gridsearch2(models2[i], X_train_todos, X_test_todos, y_train[\"TRT_60\"], y_test[\"TRT_60\"], params2[i],TODAS2)\n",
    "    SIGNIFICATIVAS2 = train_model_gridsearch2(models2[i], X_train_final, X_test_final, y_train[\"TRT_60\"], y_test[\"TRT_60\"], params2[i],SIGNIFICATIVAS2)\n",
    "    TODAS3 = train_model_gridsearch2(models2[i], X_train_todos65, X_test_todos, y_train_bi65t, y_test[\"TRT_65\"], params2[i],TODAS3)\n",
    "    SIGNIFICATIVAS3 =train_model_gridsearch2(models2[i], X_train_final65, X_test_final, y_train_bi65, y_test[\"TRT_65\"], params2[i],SIGNIFICATIVAS3)\n",
    "    TODAS4 = train_model_gridsearch2(models2[i], X_train_todos70, X_test_todos, y_train_bi70t, y_test[\"TRT_70\"], params2[i],TODAS4)\n",
    "    SIGNIFICATIVAS4 =train_model_gridsearch2(models2[i], X_train_final70, X_test_final, y_train_bi70, y_test[\"TRT_70\"], params2[i],SIGNIFICATIVAS4)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_todos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting de svc, knn y mlp\n",
    "models2 = [(\"KNN\", KNeighborsClassifier()), (\"LR\", LogisticRegression()), (\"MLP\", MLPClassifier())]\n",
    "voting = VotingClassifier(estimators=models2)\n",
    "params2 = {\"voting\": [\"hard\", \"soft\"],\"weights\": [[1,1,1],[1,2,1],[1,1,2],[1,2,2],[2,1,1],[2,2,1],[2,1,2],[2,2,2]]}\n",
    "print(\"Model: \", voting)\n",
    "TODAS2 = train_model_gridsearch2(voting, X_train_todos, X_test_todos, y_train[\"TRT_60\"], y_test[\"TRT_60\"], params2,TODAS2)\n",
    "SIGNIFICATIVAS2 = train_model_gridsearch2(voting, X_train_final, X_test_final, y_train[\"TRT_60\"], y_test[\"TRT_60\"], params2,SIGNIFICATIVAS2)\n",
    "TODAS3 = train_model_gridsearch2(voting, X_train_todos65, X_test_todos, y_train_bi65t, y_test[\"TRT_65\"], params2,TODAS3)\n",
    "SIGNIFICATIVAS3 =train_model_gridsearch2(voting, X_train_final65, X_test_final, y_train_bi65, y_test[\"TRT_65\"], params2,SIGNIFICATIVAS3)\n",
    "TODAS4 = train_model_gridsearch2(voting, X_train_todos70, X_test_todos, y_train_bi70t, y_test[\"TRT_70\"], params2,TODAS4)\n",
    "SIGNIFICATIVAS4 =train_model_gridsearch2(voting, X_train_final70, X_test_final, y_train_bi70, y_test[\"TRT_70\"], params2,SIGNIFICATIVAS4)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitar el 6 de todos los dataframes\n",
    "\n",
    "TODAS2 = TODAS2.drop([6])\n",
    "SIGNIFICATIVAS2 = SIGNIFICATIVAS2.drop([6])\n",
    "TODAS3 = TODAS3.drop([6])\n",
    "SIGNIFICATIVAS3 = SIGNIFICATIVAS3.drop([6])\n",
    "TODAS4 = TODAS4.drop([6])\n",
    "SIGNIFICATIVAS4 = SIGNIFICATIVAS4.drop([6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar los resultados en un csv\n",
    "TODAS2.to_csv(\"TODAS2.csv\", index=False)\n",
    "SIGNIFICATIVAS2.to_csv(\"SIGNIFICATIVAS2.csv\", index=False)\n",
    "TODAS3.to_csv(\"TODAS3.csv\", index=False)\n",
    "SIGNIFICATIVAS3.to_csv(\"SIGNIFICATIVAS3.csv\", index=False)\n",
    "TODAS4.to_csv(\"TODAS4.csv\", index=False)\n",
    "SIGNIFICATIVAS4.to_csv(\"SIGNIFICATIVAS4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS3.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS4.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
