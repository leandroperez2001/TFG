{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer df_sin_anomalos.csv\n",
    "import pandas as pd\n",
    "df_final = pd.read_csv(\"df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same = df_final[[\"SAME-TT2R2_MAS3\",\"TRT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_test = pd.read_csv(\"indices_test.csv\")\n",
    "indice_train = pd.read_csv(\"indices_train.csv\")\n",
    "\n",
    "df_test = df_final.iloc[indice_test[\"0\"],:]\n",
    "df_train = df_final.iloc[indice_train[\"0\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAME_test = same.iloc[indice_test[\"0\"],:]\n",
    "SAME_train = same.iloc[indice_train[\"0\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAME_X_test= SAME_test.drop(columns=[\"TRT\"])\n",
    "SAME_y_test = pd.DataFrame(SAME_test[\"TRT\"])\n",
    "\n",
    "SAME_X_train = SAME_train.drop(columns=[\"TRT\"])\n",
    "SAME_y_train = pd.DataFrame(SAME_train[\"TRT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_todos = df_test.drop(columns=[\"TRT\"])\n",
    "y_test = pd.DataFrame(df_test[\"TRT\"])\n",
    "\n",
    "X_train_todos = df_train.drop(columns=[\"TRT\"])\n",
    "y_train = pd.DataFrame(df_train[\"TRT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test_todos[[\"ARTERIOPATIA_PERIFERICA\",\"ENFERMEDAD_VASCULAR\",\"SAME_MAS_DE_2\",\"N_PASTILLAS_D_INICIO\",\"NEOPLASIA_NO\",\"ADE\",\"MONOCITOS\",\"DISLIPEMIA\",\"AMIODARONA\",\"EDAD\",\"INSUFICIENCIA_CARDIACA\",\"SAME-TT2R2_MAS3\",\"NEUTROFILOS\"]]\n",
    "X_train_final = X_train_todos[[\"ARTERIOPATIA_PERIFERICA\",\"ENFERMEDAD_VASCULAR\",\"SAME_MAS_DE_2\",\"N_PASTILLAS_D_INICIO\",\"NEOPLASIA_NO\",\"ADE\",\"MONOCITOS\",\"DISLIPEMIA\",\"AMIODARONA\",\"EDAD\",\"INSUFICIENCIA_CARDIACA\",\"SAME-TT2R2_MAS3\",\"NEUTROFILOS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacer una funcion que entrene modelos de regresion mediante gridsearch y los valide con el dataset de validacion y cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import f_oneway\n",
    "from lifelines.utils import concordance_index\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "# sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# no mostrar warnings\n",
    "import warnings\n",
    "\n",
    "# r2 ajustado\n",
    "def r2_adj(r2, n, p):\n",
    "    r2_adj = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    return r2_adj\n",
    "\n",
    "def train_model_gridsearch(model, X_train, X_val, y_train, y_val, params,DF):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring=[\"neg_root_mean_squared_error\",'neg_mean_absolute_error', 'neg_mean_squared_error', 'r2'], refit='r2')\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best params: \", grid.best_params_)\n",
    "    print(\"Best score: \", grid.best_score_)\n",
    "    start = time.time()\n",
    "    y_pred = grid.predict(X_val)\n",
    "    end = time.time()\n",
    "    print(\"Time: \", end - start)\n",
    "    print()\n",
    "    print(\"MAE: \", mean_absolute_error(y_val, y_pred))\n",
    "    # desviacion estandar de MAE\n",
    "    print(\"MAE std: \", np.std(mean_absolute_error(y_val, y_pred)))\n",
    "    print(\"MSE: \", mean_squared_error(y_val, y_pred))\n",
    "    print(\"RMSE: \", np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "    print(\"R2: \", r2_score(y_val, y_pred))\n",
    "    print(\"R2 ajustado: \", r2_adj(r2_score(y_val, y_pred), len(y_val), len(X_val.columns)))\n",
    "    print()\n",
    "\n",
    "    # residuos\n",
    "    residuos = y_val - y_pred\n",
    "\n",
    "    # crear un dataframe donde se vayan almacenando los resultados de cada modelo\n",
    "    DF = DF.append({\"Modelo\": str(model),\"R2 ajustado\":r2_adj(r2_score(y_val, y_pred), len(y_val), len(X_val.columns)),\"R2 ajustado std\": np.std(r2_adj(r2_score(y_val, y_pred), len(y_val), len(X_val.columns))),\"MAE\": mean_absolute_error(y_val, y_pred),\"MAE_std\":np.sqrt(mean_squared_error(y_val, y_pred)), \"MSE\": mean_squared_error(y_val, y_pred),\"MSE std\": np.std(mean_squared_error(y_val, y_pred)) , \"RMSE\": np.sqrt(mean_squared_error(y_val, y_pred)),\"RMSE std\": np.std(np.sqrt(mean_squared_error(y_val, y_pred))), \"R2\": r2_score(y_val, y_pred),\"R2 std\": np.std(r2_score(y_val, y_pred)), \"Time\": end - start,\"Residuos\":residuos}, ignore_index=True)\n",
    "\n",
    "    # grafico de real vs pred\n",
    "    plt.scatter(y_val, y_pred)\n",
    "    plt.title(\"Real vs Predicted\")\n",
    "    plt.xlabel(\"Real\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    # same axis 0-100\n",
    "    plt.plot([0, 100], [0, 100], 'k-', color = 'r')\n",
    "    plt.show()\n",
    "\n",
    "    # grafico de distribucion de residuos\n",
    "    sns.distplot(y_val - y_pred)\n",
    "    plt.title(\"Distribution of Residuals\")\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS = pd.DataFrame(columns=[\"Modelo\",\"R2 ajustado\",\"R2 ajustado std\", \"MAE\", \"MAE_std\",\"MSE\",\"MSE std\", \"RMSE\",\"RMSE std\", \"R2\",\"R2 std\" \"Time\",\"Residuos\"])\n",
    "TODAS = pd.DataFrame(columns=[\"Modelo\",\"R2 ajustado\",\"R2 ajustado std\", \"MAE\", \"MAE_std\",\"MSE\",\"MSE std\", \"RMSE\",\"RMSE std\", \"R2\",\"R2 std\" \"Time\",\"Residuos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAME = pd.DataFrame(columns=[\"Modelo\",\"R2 ajustado\",\"R2 ajustado std\", \"MAE\", \"MAE_std\",\"MSE\",\"MSE std\", \"RMSE\",\"RMSE std\", \"R2\",\"R2 std\" \"Time\",\"Residuos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista con los modelos a probar (linear regression, svr, neural network, decisiom tree and regresion polinomica) y sus parametros\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# voting regressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "# sequential\n",
    "# ada boost regressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "models = [SVR(), DecisionTreeRegressor(), KNeighborsRegressor(),MLPRegressor(),LinearRegression(),AdaBoostRegressor()]\n",
    "params = [{\"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \"C\": [0.1, 1, 10, 100, 1000], \"gamma\": [\"scale\", \"auto\"]},\n",
    "            {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\"], \"splitter\": [\"best\", \"random\"], \"max_depth\": [None, 1,2, 3,4, 5,6, 7, 8, 9,10]},\n",
    "            {\"n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"weights\": [\"uniform\", \"distance\"], \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]},\n",
    "            {\"hidden_layer_sizes\": [(50,50,50), (50,100,50), (100,)], \"activation\": [\"tanh\", \"relu\"], \"solver\": [\"sgd\", \"adam\"], \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]},\n",
    "            {},\n",
    "            {\"n_estimators\": [50, 100, 150, 200, 250, 300, 350, 400, 450, 500], \"learning_rate\": [0.001, 0.01, 0.1, 1, 10, 100, 1000], \"loss\": [\"linear\", \"square\", \"exponential\"]}]\n",
    "\n",
    "# entrenar los modelos con el dataset de entrenamiento y validarlos con el dataset de validacion\n",
    "for i in range(len(models)):\n",
    "    print(\"Model: \", models[i])\n",
    "    TODAS = train_model_gridsearch(models[i], X_train_todos, X_test_todos, y_train[\"TRT\"], y_test[\"TRT\"], params[i],TODAS)\n",
    "    SIGNIFICATIVAS = train_model_gridsearch(models[i], X_train_final, X_test_final, y_train[\"TRT\"], y_test[\"TRT\"], params[i],SIGNIFICATIVAS)\n",
    "    SAME = train_model_gridsearch(models[i], SAME_X_train, SAME_X_test, SAME_y_train[\"TRT\"], SAME_y_test[\"TRT\"], params[i],SAME)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTING de linear regression, knn y mlp\n",
    "models = [(\"lr\", LinearRegression()), (\"knn\", KNeighborsRegressor(n_neighbors=10)), (\"ada\", AdaBoostRegressor(learning_rate=0.01,n_estimators=150))]\n",
    "voting = VotingRegressor(estimators=models)\n",
    "params = {\"weights\": [[1,1,1], [1,2,1], [1,1,2], [1,2,2], [2,1,1], [2,2,1], [2,1,2], [2,2,2]]}\n",
    "print(\"Model: \", voting)\n",
    "TODAS = train_model_gridsearch(voting, X_train_todos, X_test_todos, y_train[\"TRT\"], y_test[\"TRT\"], params,TODAS)\n",
    "SIGNIFICATIVAS = train_model_gridsearch(voting, X_train_final, X_test_final, y_train[\"TRT\"], y_test[\"TRT\"], params,SIGNIFICATIVAS)\n",
    "SAME = train_model_gridsearch(voting, SAME_X_train, SAME_X_test, SAME_y_train[\"TRT\"], SAME_y_test[\"TRT\"], params,SAME)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICATIVAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [TODAS, SIGNIFICATIVAS]:\n",
    "    for i in range(len(TODAS)):\n",
    "        df[\"Residuos\"][i] = df[\"Residuos\"][i].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(SAME)):\n",
    "    SAME[\"Residuos\"][i] = SAME[\"Residuos\"][i].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\"SVR\", \"DT\", \"KNN\", \"MLP\", \"LR\", \"AdaBoost\", \"Voting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=SIGNIFICATIVAS[\"Residuos\"])\n",
    "plt.gca().set_xticklabels(modelos,rotation=45, ha='right')\n",
    "# cambiar el tamaño de la letra\n",
    "plt.rc('xtick', labelsize=12)\n",
    "# cambiar los labels de los ejes\n",
    "# cambiar tamaño ejes\n",
    "plt.rc('axes', labelsize=12)\n",
    "\n",
    "plt.title(\"Boxplot de Residuos\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacar la mediana y el rango intercuartilico de cada modelo\n",
    "res = {}\n",
    "for df in [TODAS,SIGNIFICATIVAS]:\n",
    "    for i in range(len(df)):\n",
    "        print(df[\"Modelo\"][i])\n",
    "        print(\"Mediana: \", np.median(df[\"Residuos\"][i]))\n",
    "        print(\"STD: \",np.std(df[\"Residuos\"][i]))\n",
    "        print(\"IQR: \", np.percentile(df[\"Residuos\"][i], 75) - np.percentile(df[\"Residuos\"][i], 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalidad de los residuos\n",
    "from scipy.stats import shapiro\n",
    "for df in [TODAS,SIGNIFICATIVAS]:\n",
    "    for i in range(len(df)):\n",
    "        print(df[\"Modelo\"][i])\n",
    "        print(shapiro(df[\"Residuos\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homogeneidad de varianzas para todos los modelos\n",
    "from scipy.stats import levene\n",
    "\n",
    "levene(df[\"Residuos\"][0], df[\"Residuos\"][1], df[\"Residuos\"][2], df[\"Residuos\"][3], df[\"Residuos\"][4], df[\"Residuos\"][5], df[\"Residuos\"][6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar un test de anova para ver si hay diferencias significativas entre los modelos\n",
    "# sacar los residuos de cada modelo\n",
    "residuos = []\n",
    "for i in range(len(SIGNIFICATIVAS)):\n",
    "    residuos.append(SIGNIFICATIVAS[\"Residuos\"][i])\n",
    "\n",
    "# test de anova\n",
    "f_oneway(*residuos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot de los residuos de cada modelo\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=SIGNIFICATIVAS[\"Residuos\"])\n",
    "plt.gca().set_xticklabels(modelos, rotation=45, ha='right')\n",
    "plt.title(\"Boxplot of Residuals\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examinar el valor atipico de cada modelo\n",
    "for i in range(len(SIGNIFICATIVAS)):\n",
    "    print(modelos[i])\n",
    "    print(sorted(SIGNIFICATIVAS[\"Residuos\"][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacar la fila del valor atipico de cada modelo\n",
    "for i in range(len(SIGNIFICATIVAS)):\n",
    "    print(modelos[i])\n",
    "    print(SIGNIFICATIVAS[\"Residuos\"][i].index(max(SIGNIFICATIVAS[\"Residuos\"][i])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analizar la fila 154\n",
    "df_final.iloc[154]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
